model_name: meta-llama/Llama-3.1-8B-Instruct
dataset_name: wikitext
dataset_dir: ./dataset
batch_size: 16
max_seq_len: 512
calib_size: 512

# pruning parameters
width_hidden: 0.43
width_intermediate: 0.43
width_attn: 0.0
depth: 0.0
batch_agg_func: l2
pruned_idx_dir: ./pruned_idx
depth_strategy: last